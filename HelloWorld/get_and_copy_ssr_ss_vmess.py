"""
Author: wanqian6311
Version: 1.0.1
Date: 2024-09-13
Description: è¯¥ç¨‹åºç”¨äºæå–å’Œæ˜¾ç¤º SSR å’Œ SS é“¾æ¥ã€‚
"""

import os  # æä¾›ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„åŠŸèƒ½ï¼Œå¦‚æ–‡ä»¶å’Œç›®å½•æ“ä½œ
import sys  # æä¾›å¯¹ Python è§£é‡Šå™¨çš„è®¿é—®ï¼Œå…è®¸ä¸è§£é‡Šå™¨è¿›è¡Œäº¤äº’
import subprocess  # å…è®¸ç”Ÿæˆå­è¿›ç¨‹å¹¶ä¸å…¶äº¤äº’
import importlib  # æä¾›åŠ¨æ€å¯¼å…¥æ¨¡å—çš„åŠŸèƒ½

def check_and_install(package):
    """æ£€æŸ¥å¹¶å®‰è£…ç¼ºå¤±çš„åŒ…"""
    try:
        importlib.import_module(package)
    except ImportError:
        print(f"æœªæ‰¾åˆ° {package}ï¼Œæ­£åœ¨å®‰è£…...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# æ£€æŸ¥å¹¶å®‰è£…æ‰€éœ€çš„åŒ…
required_packages = [
    "requests",
    "beautifulsoup4",
    "pyperclip",
    "colorama",
    "prettytable"
]

for package in required_packages:
    check_and_install(package)

# ç°åœ¨å®‰å…¨åœ°å¯¼å…¥è¿™äº›åŒ…
import requests  # ç”¨äºå‘é€ HTTP è¯·æ±‚ï¼Œè·å–ç½‘é¡µå†…å®¹
import re  # æä¾›æ­£åˆ™è¡¨è¾¾å¼æ”¯æŒï¼Œç”¨äºå­—ç¬¦ä¸²åŒ¹é…å’Œå¤„ç†
import pyperclip  # ç”¨äºå¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿
from colorama import init, Fore  # ç”¨äºåœ¨ç»ˆç«¯ä¸­è¾“å‡ºå¸¦é¢œè‰²çš„æ–‡æœ¬ï¼Œinit() åˆå§‹åŒ–ï¼ŒFore æä¾›å‰æ™¯è‰²
from prettytable import PrettyTable  # ç”¨äºåˆ›å»ºå’Œæ‰“å°ç¾è§‚çš„è¡¨æ ¼
from bs4 import BeautifulSoup  # ç”¨äºè§£æ HTML å’Œ XML æ–‡æ¡£ï¼Œæ–¹ä¾¿æå–æ•°æ®

# åˆå§‹åŒ– Colorama
init(autoreset=True)

def set_pip_source():
    # ç¡®å®šç”¨æˆ·ç›®å½•
    if os.name == 'nt':  # Windows
        pip_config_path = os.path.join(os.path.expanduser('~'), 'pip', 'pip.ini')
        os.makedirs(os.path.dirname(pip_config_path), exist_ok=True)
        with open(pip_config_path, 'w') as f:
            f.write("[global]\n")
            f.write("index-url = https://pypi.tuna.tsinghua.edu.cn/simple\n")
    else:  # Linux å’Œ macOS
        pip_config_path = os.path.join(os.path.expanduser('~'), '.pip', 'pip.conf')
        os.makedirs(os.path.dirname(pip_config_path), exist_ok=True)
        with open(pip_config_path, 'w') as f:
            f.write("[global]\n")
            f.write("index-url = https://pypi.tuna.tsinghua.edu.cn/simple\n")

def print_info():
    # æ‰“å°ç¾åŒ–åçš„ä¿¡æ¯
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  âœ¨ Author: wanqian6311                                     â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print("â•‘  ğŸ“– Blog: https://www.cnblogs.com/wanqian6311               â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print("â•‘  ğŸ™ GitHub: https://www.github/wanqian6311                  â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print("â•‘  ğŸŒŸ email: wanqian6311@163.com                              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

def test_url_accessibility(url):
    """æµ‹è¯• URL çš„å¯è®¿é—®æ€§"""
    try:
        response = requests.head(url, allow_redirects=True)  # ä½¿ç”¨ HEAD è¯·æ±‚ä»¥å‡å°‘å¸¦å®½
        return response.status_code == 200
    except requests.RequestException as e:
        print(Fore.RED + f"è¯·æ±‚é”™è¯¯: {e}")
        return False

def find_ss_links(url):
    """ä»æŒ‡å®š URL æå– SSR å’Œ SS é“¾æ¥åŠæ›´æ–°æ—¶é—´"""
    # å‘é€è¯·æ±‚
    if not test_url_accessibility(url):
        print(Fore.RED + f"æ— æ³•è®¿é—®ç½‘ç«™: {url}")
        return [], None  # è¿”å› None ä½œä¸ºæ›´æ–°æ—¶é—´

    response = requests.get(url)
    if response.status_code != 200:
        print(Fore.RED + f"æ— æ³•è®¿é—®ç½‘ç«™: {url}")
        return [], None  # è¿”å› None ä½œä¸ºæ›´æ–°æ—¶é—´

    # è§£æç½‘é¡µå†…å®¹
    soup = BeautifulSoup(response.text, 'html.parser')

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰ ssr:// å’Œ ss:// é“¾æ¥
    ssr_pattern = r'ssr://[a-zA-Z0-9_]+'
    ss_pattern = r'ss://[a-zA-Z0-9@%.#:]+'
    ss_last_modified_time =  r'åŒ—äº¬æ—¶é—´[0-9å¹´æœˆæ—¥ç‚¹æ—¶åˆ†]+'


    ssr_matches = re.findall(ssr_pattern, response.text)
    ss_matches = re.findall(ss_pattern, response.text)
    ss_last_modified_time_matches = re.findall(ss_last_modified_time, response.text)
   

    # é™åˆ¶æå–çš„é“¾æ¥é•¿åº¦
    # ssr_links = [(link[:174]) for link in ssr_matches]
    # ss_links = [(link[:110]) for link in ss_matches]
    #last_modified_time_links = [(link[4:19]) for link in last_modified_time_matches]

    return ssr_matches, ss_matches, ss_last_modified_time_matches, url


def find_vmess_links(url):
    """ä»æŒ‡å®š URL æå– SSR å’Œ SS é“¾æ¥åŠæ›´æ–°æ—¶é—´"""
    # å‘é€è¯·æ±‚
    if not test_url_accessibility(url):
        print(Fore.RED + f"æ— æ³•è®¿é—®ç½‘ç«™: {url}")
        return [], None  # è¿”å› None ä½œä¸ºæ›´æ–°æ—¶é—´

    response = requests.get(url)
    if response.status_code != 200:
        print(Fore.RED + f"æ— æ³•è®¿é—®ç½‘ç«™: {url}")
        return [], None  # è¿”å› None ä½œä¸ºæ›´æ–°æ—¶é—´

    # è§£æç½‘é¡µå†…å®¹
    soup = BeautifulSoup(response.text, 'html.parser')

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰vmess://é“¾æ¥
    vmess_pattern = r'vmess://[a-zA-Z0-9_=]+'
    vmess_last_modified_time = r'åŒ—äº¬æ—¶é—´[0-9å¹´æœˆæ—¥ç‚¹æ—¶åˆ†]+'

    vmess_matches = re.findall(vmess_pattern, response.text)

    vmess_last_modified_time_matches = re.findall(vmess_last_modified_time, response.text)


    return vmess_matches, vmess_last_modified_time_matches



def display_links(ssr_links, ss_links, ss_last_modified_time, vmess_links, vmess_last_modified_time):
    """æ˜¾ç¤º SSR å’Œ SS é“¾æ¥åŠå…¶æ›´æ–°æ—¶é—´çš„è¡¨æ ¼"""
    # åˆ›å»ºè¡¨æ ¼
    table = PrettyTable()
    table.field_names = ["åºå·", "ç±»å‹", "é“¾æ¥", "æ›´æ–°æ—¶é—´"]

    # è®¾ç½®åˆ—å®½ï¼Œå¯ç”¨è‡ªåŠ¨æ¢è¡Œ
    table.max_width["åºå·"] = 2  # è®¾ç½®æœ€å¤§å®½åº¦ä¸º2å­—ç¬¦
    table.max_width["é“¾æ¥"] = 60  # è®¾ç½®æœ€å¤§å®½åº¦ä¸º60å­—ç¬¦
  

    # è®¾ç½®æ—¶é—´æ ¼å¼
    #time1 =  ss_last_modified_time
    #time2 =  vmess_last_modified_time
    time1 = [(link[4:]) for link in ss_last_modified_time]
    time2 = [(link[4:]) for link in vmess_last_modified_time]

    # æ·»åŠ  SSR é“¾æ¥
    for i, link in enumerate(ssr_links, start=1):
        table.add_row([i, "SSR", link, time1])
        # æ·»åŠ åˆ†å‰²çº¿
        table.add_row(["----", "--------", "------------------------------------------------------------", "------------------------"])

    

    # æ·»åŠ  SS é“¾æ¥
    start_index1 = len(ssr_links) + 1  # SS é“¾æ¥çš„èµ·å§‹åºå·
    for i, link in enumerate(ss_links, start=start_index1):
        table.add_row([i, "SS", link, time1])
        # æ·»åŠ åˆ†å‰²çº¿
        table.add_row(["----", "--------", "------------------------------------------------------------", "------------------------"])

     # æ·»åŠ  vmess é“¾æ¥
    start_index2 = len(ssr_links) + len(ss_links) + 1  #  é“¾æ¥çš„èµ·å§‹åºå·
    for i, link in enumerate(vmess_links, start=start_index2):
        table.add_row([i, "Vmess", link, time2])


    # è°ƒç”¨å‡½æ•°ä»¥æ‰“å°ä¿¡æ¯
    print_info()
    print(table)

if __name__ == "__main__":
    set_pip_source()
    
    target_url_01 = "https://gitlab.com/zhifan999/fq/-/wikis/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7"
    target_url_02 = "https://fgithub.xyz/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7"
    target_url_03 = "https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7"
    target_url_vmess = "https://gitlab.com/zhifan999/fq/-/wikis/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7"
    target_url = target_url_01
    # æŸ¥æ‰¾ ssr:// å’Œ ss:// é“¾æ¥åŠæ›´æ–°æ—¶é—´
    ssr_links, ss_links, ss_last_modified_time, url = find_ss_links(target_url)
    
    vmess_links, vmess_last_modified_time = find_vmess_links(target_url_vmess)

    # æ˜¾ç¤ºé“¾æ¥
    display_links(ssr_links, ss_links, ss_last_modified_time, vmess_links, vmess_last_modified_time)
    
    # è®©ç”¨æˆ·é€‰æ‹©è¦å¤åˆ¶çš„é“¾æ¥
    while True:
        choice = input(Fore.CYAN + "è¾“å…¥åºå·é€‰æ‹©è¦å¤åˆ¶çš„é“¾æ¥ï¼Œè¾“å…¥ 0 é€€å‡º: ")
        
        if choice.isdigit():
            if choice == "0":
                break  # ç”¨æˆ·è¾“å…¥ 0 æ—¶é€€å‡º

            index = int(choice) - 1
            
            if 0 <= index < len(ssr_links):
                pyperclip.copy(ssr_links[index])  # å¤åˆ¶é“¾æ¥
                print(Fore.GREEN + f"å·²å¤åˆ¶ ssr:// é“¾æ¥: {ssr_links[index]}")
            elif len(ssr_links) <= index < len(ssr_links) + len(ss_links):
                ss_index = index - len(ssr_links)
                pyperclip.copy(ss_links[ss_index])  # å¤åˆ¶é“¾æ¥
                print(Fore.GREEN + f"å·²å¤åˆ¶ ss:// é“¾æ¥: {ss_links[ss_index]}")
            elif len(ssr_links) + len(ss_links) <= index < len(ssr_links) + len(ss_links)+ len(vmess_links):
                vmess_index = index - len(ssr_links)-len(ssr_links)
                pyperclip.copy(vmess_links[vmess_index])  # å¤åˆ¶é“¾æ¥
                print(Fore.GREEN + f"å·²å¤åˆ¶ vmess:// é“¾æ¥: {vmess_links[vmess_index]}")
            else:
                print(Fore.RED + "æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
        else:
            print(Fore.RED + "æ— æ•ˆçš„è¾“å…¥ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ•°å­—ã€‚")

    print(Fore.CYAN + "ç¨‹åºç»“æŸï¼ŒæŒ‰ä»»æ„é”®é€€å‡º...")
    input()  # ä¿æŒç»ˆç«¯æ‰“å¼€

